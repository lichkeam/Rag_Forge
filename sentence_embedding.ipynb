{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84971919",
   "metadata": {},
   "source": [
    "<H1>A Note for understanding how to convert a sentence to an embedded sentence</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29551575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1045, 2293, 8348, 5691,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "原始句子: 'I love Marvel movies'\n",
      "分詞結果: ['i', 'love', 'marvel', 'movies']\n",
      "\n",
      "Token IDs: [101, 1045, 2293, 8348, 5691, 102]\n",
      "  'i' → 1045\n",
      "  'love' → 2293\n",
      "  'marvel' → 8348\n",
      "  'movies' → 5691\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "\n",
    "# 載入 tokenizer（這是 all-MiniLM-L6-v2 使用的）\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "# print(tokenizer.all_special_tokens)\n",
    "# print(tokenizer.all_special_ids)\n",
    "# 一個句子\n",
    "sentence = \"I love Marvel movies\"\n",
    "inputs = tokenizer(sentence, return_tensors='pt')\n",
    "print(inputs)\n",
    "# 分詞\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "print(f\"原始句子: '{sentence}'\")\n",
    "print(f\"分詞結果: {tokens}\")\n",
    "\n",
    "token_ids = tokenizer.encode(sentence)\n",
    "print(f\"\\nToken IDs: {token_ids}\")\n",
    "\n",
    "# 可以看看每個 token 對應什麼 ID\n",
    "for token, token_id in zip(tokens, token_ids[1:-1]):  # 去掉特殊 token\n",
    "    print(f\"  '{token}' → {token_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c996cb",
   "metadata": {},
   "source": [
    "Token ID to token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4b4a4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token: ['[CLS]', 'i', 'love', 'marvel', 'movies', '[SEP]']\n",
      "Input IDs: tensor([[ 101, 1045, 2293, 8348, 5691,  102]])\n",
      "tensor([ 101, 1045, 2293, 8348, 5691,  102])\n",
      "Token embeddings shape: tensor([[-0.0176, -0.0076,  0.0471,  ..., -0.0545,  0.0076, -0.0617],\n",
      "        [-0.0448, -0.0583, -0.0020,  ..., -0.0494, -0.0888, -0.0592],\n",
      "        [-0.0354, -0.0099,  0.0123,  ..., -0.0080,  0.0671,  0.0367],\n",
      "        [-0.0699, -0.0008,  0.0990,  ..., -0.1430, -0.0016, -0.0637],\n",
      "        [-0.0076, -0.0655, -0.0421,  ...,  0.0339,  0.0667,  0.0039],\n",
      "        [ 0.0332, -0.0085, -0.0400,  ...,  0.0207, -0.0034, -0.0004]],\n",
      "       grad_fn=<EmbeddingBackward0>) torch.Size([6, 384])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "text = \"I love Marvel movies\"\n",
    "\n",
    "# tokenize\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "print(\"Input token:\", tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0]))\n",
    "print(\"Input IDs:\", inputs[\"input_ids\"])\n",
    "\n",
    "# 直接從模型的 word_embeddings 抓 embedding\n",
    "embedding_layer = model.embeddings.word_embeddings\n",
    "\n",
    "token_ids = inputs[\"input_ids\"][0]  # shape [seq_len]\n",
    "print(token_ids)\n",
    "# 取得 embedding\n",
    "token_embeddings = embedding_layer(token_ids)\n",
    "\n",
    "print(\"Token embeddings shape:\", token_embeddings, token_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b64621fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1]]) shape= : torch.Size([1, 6])\n",
      "Mask 形狀: torch.Size([6, 1])\n",
      "sum_mask shape =  torch.Size([1])\n",
      "\n",
      "最終句子向量形狀: torch.Size([384])\n",
      "最終句子向量前 10 個值: tensor([-0.0428, -0.0454,  0.0224,  0.0221, -0.0025,  0.0668,  0.0689,  0.0861,\n",
      "         0.0192, -0.0113], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 方法：Mean Pooling（平均池化）\n",
    "# 把所有 token 的向量平均起來\n",
    "\n",
    "# 先移除特殊 token 的 attention mask\n",
    "attention_mask = inputs['attention_mask']\n",
    "print(f\"\\nAttention Mask: {attention_mask}\", \"shape= :\", attention_mask.shape)\n",
    "\n",
    "# 只對有效的 token 做平均（排除 padding）\n",
    "mask = attention_mask.squeeze(0).unsqueeze(1)  # (6, 1)\n",
    "print(f\"Mask 形狀: {mask.shape}\")\n",
    "\n",
    "# 加權平均\n",
    "masked_embeddings = token_embeddings * mask\n",
    "sum_embeddings = torch.sum(masked_embeddings, dim=0)  # 在 token 維度上加總\n",
    "sum_mask = torch.clamp(mask.sum(dim=0), min=1e-9)     # 避免除以 0\n",
    "print(\"sum_mask shape = \", sum_mask.shape)\n",
    "# 最終的句子向量\n",
    "sentence_embedding = sum_embeddings / sum_mask\n",
    "sentence_embedding = sentence_embedding / sentence_embedding.norm(p=2) #normalization\n",
    "sentence_embedding = sentence_embedding.to(\"cuda\")\n",
    "print(f\"\\n最終句子向量形狀: {sentence_embedding.shape}\")\n",
    "print(f\"最終句子向量前 10 個值: {sentence_embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd0d39d",
   "metadata": {},
   "source": [
    "<H3>Cosine Similarity Test</H3>\n",
    "<H4>Cosine Similarity Range\tMeaning</H4>\n",
    "<p>0.85 ~ 1.0:\tVery similar, almost semantically identical<br>  \n",
    "0.7 ~ 0.85:\tHighly related, meaning is close<br>  \n",
    "0.5 ~ 0.7:\tModerately similar, some semantic overlap<br>  \n",
    "0.3 ~ 0.5:\tLow similarity, weak semantic relation<br>  \n",
    "< 0.3:\tAlmost unrelated, little to no semantic connection</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f48f332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "39d376c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ['Who is the main character in Iron Man?', 'Who is Tony stark?']\n",
      "\n",
      "Doc 0: Iron Man is a Marvel superhero film about Tony Stark  ->  Cosine similarity: 0.1851\n",
      "Doc 1: The recipe for chocolate cake is very simple  ->  Cosine similarity: 0.0458\n",
      "Doc 2: Avengers Endgame is an epic superhero movie  ->  Cosine similarity: 0.2421\n",
      "Doc 3: Python is a programming language  ->  Cosine similarity: 0.0806\n",
      "Doc 4: Captain America fights for justice  ->  Cosine similarity: 0.1441\n",
      "\n",
      "Most similar document: Avengers Endgame is an epic superhero movie (score=0.2421)\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "documents = [\n",
    "    \"Iron Man is a Marvel superhero film about Tony Stark\",\n",
    "    \"The recipe for chocolate cake is very simple\",\n",
    "    \"Avengers Endgame is an epic superhero movie\",\n",
    "    \"Python is a programming language\",\n",
    "    \"Captain America fights for justice\"\n",
    "]\n",
    "\n",
    "\n",
    "query = [\"Who is the main character in Iron Man?\",\"Who is Tony stark?\"]\n",
    "\n",
    "\n",
    "# 文檔 embeddings\n",
    "doc_embeddings = model.encode(documents, convert_to_tensor=True)  # shape [5, embedding_dim]\n",
    "\n",
    "\n",
    "# query embedding\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)  # shape [embedding_dim]\n",
    "# print(sentence_embedding.unsqueeze(0))\n",
    "\n",
    "# cosine similarity: query 與每個 document\n",
    "# cos_scores = F.cosine_similarity(query_embedding.unsqueeze(0), doc_embeddings)\n",
    "cos_scores = F.cosine_similarity(sentence_embedding.unsqueeze(0), doc_embeddings)\n",
    "# 排序\n",
    "top_idx = torch.argmax(cos_scores)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"Doc {i}: {doc}  ->  Cosine similarity: {cos_scores[i]:.4f}\")\n",
    "\n",
    "print(f\"\\nMost similar document: {documents[top_idx]} (score={cos_scores[top_idx]:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
